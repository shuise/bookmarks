<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/><meta name="exporter-version" content="Evernote Mac 7.9 (457564)"/><meta name="author" content="水色"/><meta name="created" content="2016-06-01 09:59:05 +0000"/><meta name="source" content="desktop.mac"/><meta name="updated" content="2018-07-20 02:07:25 +0000"/><meta name="reminder-order" content="2018-07-30 01:08:06 +0000"/><meta name="reminder-done-time" content="2019-01-04 13:44:55 +0000"/><title>《哥德尔，埃舍尔和巴赫》</title></head><body><div>必须指出，原则上把信息编码成数据结构或过程的任何方式都是同好的，也就是说如果你不在意效率的话，你能用一种方式所做的一切也都能用另外一种方式来做。但是，可以提出一些理由来说明一种方式似乎肯定比另外一种优越。</div><div>例如，请考虑下面主张使用过程性表示的论点：“一旦你想要把相当复杂的特性<span style="font-weight: bold;">编码在数据</span>中，你就不得不开发出一种新的语言或者新的形式系统的东西。因此实际上你的数据结构变得像程序，而你的一些程序成了他们的解释程序，那你还不如开始就直接把这些信息表示成过程的形式，这样就用不着外层的解释程序了。”</div><div><br/></div><div><br/></div><div><br/></div><div>“集聚”与“过滤”</div><div><br/></div><div>“集聚”是指构造这样一些描述，其焦点是框中图像的某一部分，而排除其他部分。</div><div>“过滤”是指构造这样一些描述，他以某种特定的方式来观察框的内容，而完全不顾其他方面。</div><div><br/></div><div>这二者是互补的。</div><div><br/></div><div>邦加德《模式识别》</div><div>《格式塔心理学》</div><div><br/></div><div><br/></div><div>图像识别：</div><div>1：在照片中寻找事先说明的物体</div><div>2：把一副图像分解成独立的物体</div><div>3：在一副图像中辨别出独立的物体</div><div>4：根据人提供的简图识别物体</div><div>5：识别人的面容</div><div><br/></div><div><br/></div><div>在任何别的场合，当你碰到一句包含有“我”的话语，你是否还能自然而然的认为它不是指说这句话的人，而是指这句话本身？我猜这种可能性很小。“我”这个词如果出现在莎士比亚的一首十四行诗里，那它指的绝不是印在纸上的这十四行诗，而是指幕后那个有血有肉的人，这个人是不在场的。</div><div>我们通常把一句话里的“我”追溯到多远呢？其答案在我看来是我们要找到一个有感知力的主体，认为ta就是说这句话的人。但什么是有感知力的主体呢？是指我们可以方便的拟人化的东西。在魏增保姆的“医生”程序中，是否存在一个人格呢？如果存在，那是谁的？关于这个问题的一场小型论战近来正在《科学》杂志上激烈的进行着。</div><div><br/></div><div><br/></div><div>思维的每一个方面，都可以看成是从较高的层次描述一个位于较底层，受某些简单的乃至形式的规则支配的系统。当然，这个“系统”就是大脑——除非谈论的是在另一种媒质（比如一台计算机的电路）中流动的思维过程。形象的说，这是一个支撑着“非形式系统”的形式系统，那么非形式系统能一语双关，能发现数字中的模式，会忘记人的姓名，会走臭棋等等。我们从外部看到的是它的非形式化的，公开的，软件的层次。作为对照，它还是一个形式化的，隐蔽的，硬件的层次（或者叫基质），这是一部令人望而生畏的机器，它根据物理地嵌入其中的某些确定的规则以及与之密切相连的信号输入，在各个状态之间进行转换。</div><div><br/></div><div><br/></div><div>这种“主观想象出的世界”的构造过程产生的如此随意自然，以至于我们几乎没有注意到自己在做什么，我们从自己的幻想中选出一个世界，它在某种内在精神意义下接近于真实世界。我们把真实的东西和我们感觉差不多真实的东西相互比较。这样，我们得到了某种难以捉摸的对实在的看法。</div><div>斯坦纳：“从我们已有的知识推测，假如没有这种幻想的，虚拟的，反决定论的语言工具，没有产生并储存在大脑皮质的多余部分中的语义能力，并以此来想象和表达那些在单调沉闷的生物性衰退和死亡之外的各种可能性，人类是几乎不可能生存至今的。”</div><div><br/></div><div><br/></div><div>问题分解——&gt; 中间目标 ———&gt; 新的问题空间</div><div><br/></div><div>超前搜索与局部目标</div><div><br/></div><div>问题空间，简单化与复杂化</div><div><br/></div><div>反向链接，保持通向你所储存经验的路径是很重要的。</div><div><br/></div><div>有一个与人工智能的进度相关的“定理”：一旦某些心智功能被程序化了，人们很快就不再把它看作是“真正的思维”的一种本质成分，智能所固有的核心永远是存在于那些尚未程序化的东西之中。也就是说，人工智能是尚未能做到的东西。</div><div><br/></div><div><br/></div><div>时至今日，人们在从不同的角度处理下棋问题，其中最新颖的想法之一就是认为超前搜索是劳而无功的，反之，我们只需要看看当前的局势是怎么样的，并使用某些启发式规则生成的一个计划，然后寻找一个能推进这个特定计划的棋步。当然，下期计划的形成规则中必须要包括一些启发式知识，他们在某种意义下是超前搜索的“压缩”形式，这就是说，在需要盘棋中的超前搜索经验的等价物被“凝固”成另外一种形式，而这种形式表面上并不需要超前搜索。在某种意义下这是个文字游戏。但如果这种压缩的知识在提供回答是比实际的超前搜索更有效，即使它偶尔会误入歧途也罢，那我们就已经有所收获了。象这样把知识蒸馏成更有效的形式，正是研究时的一条行之有效的路径。尤其吸引人的想法是设计这样一个横须，它自己能把从超前搜索中得到的知识变成压缩的规则，但这是个艰巨的任务。</div><div><br/></div><div>你怎样才能确切的知道你是在朝着一条定理前进？而不是在毫无意义的空转呢？这是我系统能通过WU问题加以描述的东西之一，当然，不可能存在确定的答案，而这正是那些限制性定理的内容。因为如果你总能知道应该走那条路，你也就能构造一个算法来证明所需的定理了，这就样违反了丘奇定理。这样的算法是不存在的。但是，这并不意味着不可能产生出任何关于那条路有希望，那条路没希望的直觉来。事实上，最好的程序都是很负责的启发式知识，使他们在进行谓词演算的演绎推理时，其速度能和训练有素的人想媲美。</div><div><br/></div><div><br/></div><div><br/></div><div>在某种意义下，所有问题都可以说是抽象化了的狗与骨头问题。许多问题都不是针对于物理空间，二是针对于某种概念空间的。当你认识到直接指向目标的行动在哪个空间中会使你碰上某种抽象的“栅栏”，你可能会在下列两种办法中选择一种：1 试着以某种随机的方式离开目标，希望你会发现一个隐蔽的门，你可以通过它跑到骨头跟前去； 2 设法发现一个新的问题表示“空间”，在其中没有抽象的栅栏把你和你的目标隔开，然后你就可以在这个新空间中直接跑向目标了。</div><div><br/></div><div>第一种方法似乎太慢，而第二种方法似乎太困难，太复杂。然而，那些涉及到重建问题空间的答案多半是一种突然闪现的洞见，而不是一系列缓慢，审慎的思维过程的产物。也许这些直觉的火花就是来自智能的核心，不必说，他们的来源是我们满怀戒意的大脑所严格保守的一个秘密。</div><div><br/></div><div>在任何情况下，麻烦都不在于问题分解本身可能导致错误，它可以说是做好的技术，真正的难题比这个还要深刻，你怎样为问题选择一个良好的内部表示呢？你是在一个什么样的“空间”中观察它呢？在你已经选好的空间中，你用哪种行动来缩短你和你的目标之间的“距离”？这可以用数学语言表示成一个在状态之间寻找适当的“度量”（距离函数）的问题。你要找到这样一个度量，在这种度量之下你和你的目标的距离最短。</div><div><br/></div><div>现在既然选择一个内部表示这件事本身又是一种问题，而且也是最复杂的问题，你可能会想到用问题分解技术转过来对付它。为了做到这一点，你必须用某种方式表示许多不同的抽象空间，这是一项极其复杂的工作。我不知道是否已经有人在这些方向上进行过尝试。这可能仅仅是一种理论上有趣并吸引人的建议，实际上完全不现实。</div><div><br/></div><div>不管怎么说，人工智能需要这样一种程序，他们能够“后退几步”，看看正在发生什么事，并且根据观察重新调整方向，以完成手边的任务。不难编写一个擅长于某项单一工作的程序，这项工作当由人来完成时似乎是需要智能的，但这完全不同于编写一个智能程序。这两者间的差别就如同黄蜂，他们的先天本能行为看上去会使人误以为他们具有很高的智能，和观察黄蜂的人之间的差别一样。</div><div><br/></div><div><br/></div><div><br/></div></body></html>